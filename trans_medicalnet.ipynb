{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import Tensor, nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from tqdm.auto import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "from pretrained.models.medicalnet import resnet10\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __conv_subblock(self, in_channels: int, out_channels: int):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 1, 1),\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "            ),\n",
    "            nn.Conv3d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(3, 1, 1),\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "            ),\n",
    "            nn.Conv3d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 3, 1),\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "            ),\n",
    "            nn.Conv3d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=(1, 1, 3),\n",
    "                stride=1,\n",
    "                padding=\"same\",\n",
    "            ),\n",
    "            nn.BatchNorm3d(out_channels),\n",
    "        )\n",
    "\n",
    "    def __init__(\n",
    "        self, pooling: bool = True, io_channels: int = 16, latent_channels: int = 8\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.subblock1 = self.__conv_subblock(io_channels, latent_channels)\n",
    "        self.lr1 = nn.LeakyReLU()\n",
    "        self.subblock2 = self.__conv_subblock(latent_channels, io_channels)\n",
    "        self.lr2 = nn.LeakyReLU()\n",
    "\n",
    "        if pooling:\n",
    "            self.pooling = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=2)\n",
    "        else:\n",
    "            self.pooling = nn.Identity()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        identity = x\n",
    "\n",
    "        out = self.subblock1(x)\n",
    "        out = self.lr1(out)\n",
    "        out = self.subblock2(out)\n",
    "\n",
    "        out += identity\n",
    "        out = self.lr2(out)\n",
    "\n",
    "        out = self.pooling(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransMedicalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        state_dict = torch.load(\n",
    "            \"pretrained/weights/medicalnet_resnet_10_23dataset.pth\"\n",
    "        )[\"state_dict\"]\n",
    "        state_dict = OrderedDict({k[7:]: v for k, v in state_dict.items()})\n",
    "\n",
    "        self.medicalnet = resnet10(\n",
    "            sample_input_D=192,\n",
    "            sample_input_H=256,\n",
    "            sample_input_W=256,\n",
    "            num_seg_classes=2,\n",
    "        )\n",
    "        self.medicalnet.conv_seg = nn.Identity()\n",
    "        self.medicalnet.load_state_dict(state_dict)\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv3d(512, 8, kernel_size=(1, 1, 1), stride=1, padding=\"same\"),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # self.init_block = nn.Sequential(\n",
    "        #     nn.Conv3d(4, 16, kernel_size=(3, 3, 3), stride=2),\n",
    "        #     nn.BatchNorm3d(16),\n",
    "        #     nn.ReLU(),\n",
    "        # )\n",
    "\n",
    "        # self.conv1 = ResidualBlock()\n",
    "        # self.conv2 = ResidualBlock(pooling=False)\n",
    "\n",
    "        self.global_pooling = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "\n",
    "        self.readout_block = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8, 32, bias=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 2, bias=True),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        for p in self.medicalnet.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.bottleneck.apply(init_weights)\n",
    "        # self.conv1.apply(init_weights)\n",
    "        # self.conv2.apply(init_weights)\n",
    "        self.global_pooling.apply(init_weights)\n",
    "        self.readout_block.apply(init_weights)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        out = self.medicalnet(x)\n",
    "        out = self.bottleneck(out)\n",
    "        # out = self.init_block(out)\n",
    "        # out = self.conv1(out)\n",
    "        # out = self.conv2(out)\n",
    "        out = self.global_pooling(out)\n",
    "        out = self.readout_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "patience = 3\n",
    "\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hareen/Projects/flowerpots/pretrained/models/medicalnet.py:171: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode=\"fan_out\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "TransMedicalNet                               [2, 2]                    --\n",
       "├─ResNet: 1-1                                 [2, 512, 24, 32, 32]      --\n",
       "│    └─Conv3d: 2-1                            [2, 64, 96, 128, 128]     (21,952)\n",
       "│    └─BatchNorm3d: 2-2                       [2, 64, 96, 128, 128]     (128)\n",
       "│    └─ReLU: 2-3                              [2, 64, 96, 128, 128]     --\n",
       "│    └─MaxPool3d: 2-4                         [2, 64, 48, 64, 64]       --\n",
       "│    └─Sequential: 2-5                        [2, 64, 48, 64, 64]       --\n",
       "│    │    └─BasicBlock: 3-1                   [2, 64, 48, 64, 64]       (221,440)\n",
       "│    └─Sequential: 2-6                        [2, 128, 24, 32, 32]      --\n",
       "│    │    └─BasicBlock: 3-2                   [2, 128, 24, 32, 32]      (672,512)\n",
       "│    └─Sequential: 2-7                        [2, 256, 24, 32, 32]      --\n",
       "│    │    └─BasicBlock: 3-3                   [2, 256, 24, 32, 32]      (2,688,512)\n",
       "│    └─Sequential: 2-8                        [2, 512, 24, 32, 32]      --\n",
       "│    │    └─BasicBlock: 3-4                   [2, 512, 24, 32, 32]      (10,750,976)\n",
       "│    └─Identity: 2-9                          [2, 512, 24, 32, 32]      --\n",
       "├─Sequential: 1-2                             [2, 8, 24, 32, 32]        --\n",
       "│    └─Conv3d: 2-10                           [2, 8, 24, 32, 32]        4,104\n",
       "│    └─ReLU: 2-11                             [2, 8, 24, 32, 32]        --\n",
       "├─AdaptiveAvgPool3d: 1-3                      [2, 8, 1, 1, 1]           --\n",
       "├─Sequential: 1-4                             [2, 2]                    --\n",
       "│    └─Flatten: 2-12                          [2, 8]                    --\n",
       "│    └─Linear: 2-13                           [2, 32]                   288\n",
       "│    └─Dropout: 2-14                          [2, 32]                   --\n",
       "│    └─Linear: 2-15                           [2, 2]                    66\n",
       "│    └─Softmax: 2-16                          [2, 2]                    --\n",
       "===============================================================================================\n",
       "Total params: 14,359,978\n",
       "Trainable params: 4,458\n",
       "Non-trainable params: 14,355,520\n",
       "Total mult-adds (Units.GIGABYTES): 849.60\n",
       "===============================================================================================\n",
       "Input size (MB): 100.66\n",
       "Forward/backward pass size (MB): 6143.61\n",
       "Params size (MB): 57.44\n",
       "Estimated Total Size (MB): 6301.71\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = TransMedicalNet().to(device)\n",
    "summary(model, input_size=(batch_size, 1, 192, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"images.csv\")\n",
    "df_train, df_test = train_test_split(\n",
    "    df, test_size=2 / 10, stratify=df[\"score\"], random_state=random_state\n",
    ")\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train, test_size=1 / 8, stratify=df_train[\"score\"], random_state=random_state\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(MRIDataset(df_train), batch_size=batch_size)\n",
    "loader_val = DataLoader(MRIDataset(df_val), batch_size=batch_size)\n",
    "loader_test = DataLoader(MRIDataset(df_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "es = EarlyStopping(patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2870e88db8a44e30859b00528f9110f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: val_loss=0.77482670545578, early_stopping_count=0\n",
      "Epoch 1: val_loss=0.7038728594779968, early_stopping_count=0\n",
      "Epoch 2: val_loss=0.710848331451416, early_stopping_count=1\n",
      "Epoch 3: val_loss=0.6841521263122559, early_stopping_count=0\n",
      "Epoch 4: val_loss=0.6836827993392944, early_stopping_count=0\n",
      "Epoch 5: val_loss=0.6807718276977539, early_stopping_count=0\n",
      "Epoch 6: val_loss=0.6788797974586487, early_stopping_count=0\n",
      "Epoch 7: val_loss=0.6805113554000854, early_stopping_count=1\n",
      "Epoch 8: val_loss=0.680249810218811, early_stopping_count=2\n",
      "Epoch 9: val_loss=0.6839407086372375, early_stopping_count=3\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    for X, y in loader_train:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        pred = model(X)\n",
    "        cost = loss_fn(pred, y)\n",
    "        cost.backward()\n",
    "        opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = sum(\n",
    "            loss_fn(model(X.to(device)), y.to(device)) for X, y in loader_val\n",
    "        )\n",
    "\n",
    "    es.evaluate(model, val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}: val_loss={val_loss / len(loader_val)}, early_stopping_count={es.counter}\")\n",
    "\n",
    "    if es.should_stop():\n",
    "        model = es.load_best(model)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_raw = []\n",
    "y_pred_raw = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in loader_test:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "\n",
    "        y_true_raw.append(y)\n",
    "        y_pred_raw.append(pred)\n",
    "\n",
    "y_true_raw = torch.concatenate(y_true_raw).cpu().numpy()\n",
    "y_pred_raw = torch.concatenate(y_pred_raw).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1]),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_true_raw.argmax(axis=1)\n",
    "y_pred = y_pred_raw.argmax(axis=1)\n",
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  0],\n",
       "       [35,  5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
